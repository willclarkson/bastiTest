{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017-09-09 Mitigating the wrapping of deltas in BaSTi synthetic populations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wiclarks@umich.edu - started 2017-09-09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:** Develop and test a simple (ad hoc) strategy to characterize synthetic stellar population $\\Delta M$~in the presence of possible imposition of a hard limit and wrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Results and indications #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(To be included when done.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plan #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming some 1D sample-set $x$~is drawn from a symmetric underlying distribution, so that the mean $\\langle x \\rangle$~and median $x_m$~can be expected to roughly coincide in a sample with $N$~objects, the sample variance $\\epsilon^2$~can be estimated following\n",
    "\\begin{eqnarray}\n",
    "    \\epsilon^2 & \\equiv & \\frac{1}{N-1}\\sum^{\\rm all}_{i=1} \\left( x_i - \\langle x \\rangle \\right)^2 \\\\\n",
    "    & \\approx & \\frac{1}{N-1} \\left[ \\sum^{\\lt x_m}_i \\left( x_i - x_m \\right)^2 \n",
    "    + \\sum^{\\ge x_m}_i \\left( x_i - x_m \\right)^2 \\right] \\\\\n",
    "    & \\simeq & \\frac{2}{N-1} \\sum^{\\lt x_m}_i \\left( x_i - x_m \\right)^2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(1)\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where for the final line we assume that $N(\\lt x_m) \\approx N(\\ge x_m)$ and that the two samples above and below $x_m$ are similar in magnitude.\n",
    "\n",
    "If we insist that $N(\\lt x_m) = N(\\ge x_m) = N/2$, and also (equivalently?) that $N$ is large, then we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "    \\epsilon^2 & \\approx & \\frac{1}{N(< x_m)} \\sum^{\\lt x_m}_i \\left( x_i - x_m \\right)^2 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(2) \n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the applications I have in mind, $N$~will typically be in the hundreds; i.e. $N-1 \\approx N$, etc.\n",
    "\n",
    "(This must be a standard result, I don't have my stats books to hand just this moment...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to produce the estimate:\n",
    "1. Classify objects into those \"impacted\" by the boundary condition, and otherwise, possibly using external information;\n",
    "2. Estimate the median $x_m$~of the underlying distribution, allowing for censored data;\n",
    "3. Identify the objects on the same side of $x_m$~as the majority of the non-\"impacted\" points;\n",
    "4. Estimate $\\epsilon^2$~following expression (1) above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tricky part is likely going to be estimating $x_m$ with censored data, since there is no guarantee that (say) a single Gaussian will describe the data. I adopt the ad-hoc approach of fitting a Gaussian to the histogram of the deltas selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific use-case is to examine $\\Delta M$ from sequences fit to BaSTi synthetic stellar populations. Several aspects (e.g. the data to use when working out what's censored) come across with these particular data tables. Hopefully it's obvious how to generalize this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Python modules ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import a few needed things\n",
    "from astropy.table import Table, Column\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the fitter we will use to find the peak\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for plotting\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use snazzy styles / allow light-colored scatter-points to be visible?\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Location of datafiles ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirDeltas = './outputs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define methods #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_gauss1d(x, mean, sigma, norm):\n",
    "    \n",
    "    \"\"\"1D gaussian\"\"\"\n",
    "    \n",
    "    powr = 0.5 * ((x - mean)/sigma)**2\n",
    "    cons = norm * 1.0 / (sigma * np.sqrt(2.0 * np.pi))\n",
    "    \n",
    "    return cons * np.exp(0. - powr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findVarianceSymm(tDeltas, limitColumn='fehSel', valuColumn='deltaMag', \\\n",
    "                    nBins=30, nBinsFit=25, isoSet='ss', \\\n",
    "                    printDispersions=True, \\\n",
    "                    limitValues = {'ss':[-2.27, 0.40], 'al':[-2.67, 0.05]}, \\\n",
    "                    showFigure=False, \\\n",
    "                    alphaAvoid = 0.7, \\\n",
    "                    showExclude=True, \\\n",
    "                    sLabelLim=r'[Fe/H]', sTitle=''):\n",
    "    \n",
    "    \"\"\"Method that wraps the cell-by-cell analysis we did in v1 of this notebook\"\"\"\n",
    "    \n",
    "    # We could come back and refactor this into methods later... for the moment \n",
    "    # let's stick with this laundry list to avoid passing arguments back and forth.\n",
    "    \n",
    "    # find objects that are near a boundary\n",
    "    bLo = tDeltas[limitColumn] < limitValues[isoSet][0]\n",
    "    bHi = tDeltas[limitColumn] >= limitValues[isoSet][-1]\n",
    "    bOK = (~bLo) & (~bHi)\n",
    "    \n",
    "    # Produce the pieces we'll need to compute and draw the histogram\n",
    "    vDeltas = tDeltas[valuColumn]\n",
    "    xRange = [np.min(vDeltas), np.max(vDeltas)]\n",
    "    \n",
    "    # compare the mean and median to decide which \"bad\" case we have here\n",
    "    xMed = np.median(vDeltas)\n",
    "    xMean = np.mean(vDeltas)\n",
    "    usingHi = True\n",
    "    if xMed < xMean:\n",
    "        bBad = np.copy(bHi)\n",
    "        usingHi=True\n",
    "        iNudge = 1\n",
    "    else:\n",
    "        bBad = np.copy(bLo)\n",
    "        usingHi=False\n",
    "        iNudge = -1\n",
    "        \n",
    "    # compute the histogram, find the argmax and the object next to it\n",
    "    histBad, edgesBad = np.histogram(vDeltas[bBad], bins=nBins, range=xRange)\n",
    "\n",
    "    iBig = np.argmax(histBad)\n",
    "    limUpperBad = edgesBad[iBig+iNudge]\n",
    "\n",
    "    # now that we have our limit, this time compute the histogram of the \"OK\" values\n",
    "    \n",
    "    if usingHi:\n",
    "        bToFit = (bOK) & (vDeltas > limUpperBad)\n",
    "    else:\n",
    "        bToFit = (bOK) & (vDeltas < limUpperBad)\n",
    "        \n",
    "    # allow a different binning for this histogram!\n",
    "    histFit, edgesFit = np.histogram(vDeltas[bToFit], nBinsFit)\n",
    "    medsFit = 0.5 * (edgesFit[0:-1] + edgesFit[1::])\n",
    "    histFit = np.array(histFit, 'float')\n",
    "    \n",
    "    # now try a fit using curve_fit. Construct guess parameters\n",
    "    guess = np.array([np.median(vDeltas[bToFit]), np.std(vDeltas[bToFit]), np.max(histFit) ])\n",
    "    bounds = ([xRange[0], 0., 0.], [xRange[1], xRange[1]-xRange[0], np.max(histFit)*5.])\n",
    "\n",
    "    popt, pcov = curve_fit(f_gauss1d, medsFit, histFit,\\\n",
    "                           p0=guess, \\\n",
    "                          bounds=bounds)\n",
    "\n",
    "    # now find the variance of the points in the half we're using\n",
    "    if usingHi:\n",
    "        bForStat = (bOK) & (vDeltas > popt[0])\n",
    "    else:\n",
    "        bForStat = (bOK) & (vDeltas < popt[0])\n",
    "    \n",
    "    varOnesided = np.sum( (vDeltas[bForStat] - popt[0])**2 ) / np.float(np.sum(bOK)-1.0)\n",
    "\n",
    "    # or, we could just use our one-sided samples directly\n",
    "    varHalf = np.sum( (vDeltas[bForStat] - popt[0])**2 ) / np.float(np.sum(bForStat))\n",
    "    \n",
    "    if printDispersions:\n",
    "        print \"INFO - expression (1):  %.3f\" % (np.sqrt(varOnesided * 2.0))\n",
    "        print \"INFO - expression (2):  %.3f\" % (np.sqrt(varHalf))\n",
    "        print \"INFO - Gaussian approx: %.3f\" % (popt[1])\n",
    "    \n",
    "    if showFigure:\n",
    "        # set up the figure\n",
    "        fig1 = plt.figure(1, figsize=(12,7))\n",
    "        fig1.clf()\n",
    "\n",
    "        # some labels\n",
    "        sLabelX = r'$\\Delta M$'\n",
    "        sLabelY = r'N(%s)' % (sLabelX)\n",
    "\n",
    "        # set up for the stacked histogram\n",
    "        lLabels = ['%s Between limits' % (sLabelLim), '%s outside range' % (sLabelLim)]\n",
    "        lColos = ['g', 'm']\n",
    "        \n",
    "        ax1 = fig1.add_subplot(1,2,1)\n",
    "        ax2 = fig1.add_subplot(2,2,2, sharex=ax1)\n",
    "        ax3 = fig1.add_subplot(2,2,4, sharex=ax1)\n",
    "\n",
    "        # try stacked histogram\n",
    "        vStack = [vDeltas[bOK], vDeltas[bBad]]\n",
    "        \n",
    "        nAll, binsAll, patchesAll = \\\n",
    "            ax1.hist(vStack, nBins, range=xRange, alpha=0.5, color=lColos, stacked=True, \\\n",
    "                     zorder=5, label=lLabels, rwidth=1.)\n",
    "#            ax1.hist(vDeltas, nBins, range=xRange, alpha=0.5, color='0.1', \\\n",
    "#                    stacked=True, label='Entire sample', zorder=5)\n",
    "    \n",
    "        nOK, binsOK, patchesOK = \\\n",
    "            ax2.hist(vDeltas[bOK], nBins, range=xRange, alpha=0.5, color=lColos[0], \\\n",
    "                     label=lLabels[0], zorder=5)\n",
    "        nHi, binsHi, patchesHi = \\\n",
    "            ax3.hist(vDeltas[bBad], nBins, range=xRange, alpha=0.5, \\\n",
    "                     color=lColos[1], label=lLabels[1], zorder=5)\n",
    "            \n",
    "        if showExclude:\n",
    "            for thisAx in [ax2, ax3]:\n",
    "                xRang2 = np.copy(thisAx.get_xlim())\n",
    "                yRang2 = np.copy(thisAx.get_ylim())\n",
    "\n",
    "                # ensure there's room for the legend (not sure why this isn't working)\n",
    "                yRang2[-1] += 40\n",
    "                \n",
    "                # the limits depend on which direction we're going.\n",
    "                polY2 = np.array([yRang2[0], yRang2[0], yRang2[1], yRang2[1], yRang2[0]])\n",
    "                if usingHi:\n",
    "                    polX2 = np.array([xRang2[0], limUpperBad, limUpperBad, xRang2[0], xRang2[0]])            \n",
    "                else:\n",
    "                    polX2 = np.array([limUpperBad, xRang2[-1], xRang2[-1], limUpperBad, limUpperBad])\n",
    "\n",
    "                thisAx.fill(polX2, polY2, color='0.7', alpha=alphaAvoid, zorder=1)\n",
    "                thisAx.plot(polX2, polY2, color='0.1', alpha=0.9, zorder=15, ls='--', lw=2)\n",
    "                thisAx.set_xlim(xRang2)\n",
    "                thisAx.set_ylim(yRang2)\n",
    "\n",
    "                \n",
    "        # if it's been fit, overplot our fitted distribution\n",
    "        xSet = np.copy(ax2.get_xlim())\n",
    "        xFine = np.linspace(xSet[0], xSet[-1], 1000)\n",
    "        dumShow = ax2.plot(xFine, f_gauss1d(xFine, *popt) * float(nBinsFit)/float(nBins), \\\n",
    "                           lw=4, color='0.2', alpha=0.5, label='Smooth fit')\n",
    "                \n",
    "        for axX in [ax1, ax3]:\n",
    "            axX.set_xlabel(sLabelX)\n",
    "        for thisAxis in [ax1, ax2, ax3]:\n",
    "            legThis = thisAxis.legend(frameon=True)\n",
    "            legThis.get_frame().set_facecolor('w')\n",
    "            legThis.set_zorder(55)\n",
    "    \n",
    "            thisAxis.set_ylabel(sLabelY)\n",
    "    \n",
    "        if len(sTitle) > 0:\n",
    "            fig1.suptitle(sTitle)\n",
    "    \n",
    "    return varHalf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrapGetStd(filDeltas='testMetRich_deltas.fits', isoSet='ss'):\n",
    "    \n",
    "    \"\"\"Convenient one-liner to do the analysis\"\"\"\n",
    "    \n",
    "    tDeltas = Table()\n",
    "    pathDeltas = '%s/%s' % (dirDeltas, filDeltas)\n",
    "    if not os.access(pathDeltas, os.R_OK):\n",
    "        print \"WARN - cannot access input path %s\" % (pathDeltas)\n",
    "        return\n",
    "        \n",
    "    tDeltas = Table.read(pathDeltas)\n",
    "    varHalf = findVarianceSymm(tDeltas, isoSet=isoSet, showFigure=True, \\\n",
    "                              sTitle=filDeltas)\n",
    "    \n",
    "    return np.sqrt(varHalf)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Do the analyses #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filDeltas = 'testMetRich_deltas.fits'\n",
    "isoSet = 'ss'\n",
    "\n",
    "# try the halo metal-poor\n",
    "#filDeltas = 'haloMetalPoor_deltas.fits'\n",
    "# isoSet = 'al'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - expression (1):  0.141\n",
      "INFO - expression (2):  0.131\n",
      "INFO - Gaussian approx: 0.119\n"
     ]
    }
   ],
   "source": [
    "stdHalf = wrapGetStd(filDeltas, isoSet=isoSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
